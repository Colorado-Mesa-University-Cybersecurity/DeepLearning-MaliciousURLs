{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python_defaultSpec_1598549735847",
      "display_name": "Python 3.8.3 64-bit ('base': conda)"
    },
    "colab": {
      "name": "models with feature selection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "GGiJraoIKFJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c54597cc-a571-4439-a284-1abec88373b2"
      },
      "source": [
        "# Import the dataset saved on the google drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Graphing capabilities\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data management\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# For stratified 10-fold cross validation\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Scikit-Learn ML Models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Keras-TensorFlow DNN Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import BatchNormalization, Dense, Dropout\n",
        "from keras.regularizers import l2\n",
        "\n",
        "# Fast.ai DNN Model\n",
        "from fastai.tabular import *\n",
        "\n",
        "# Normalization\n",
        "from keras.utils import normalize, to_categorical\n",
        "\n",
        "print('Imports complete.')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imports complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQYKlqkpLDMd",
        "colab_type": "text"
      },
      "source": [
        "## Functions Used\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbAgDpjvKFKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_eval_on(X, y, feature_set):\n",
        "    \"\"\"\n",
        "    train_and_eval_on function\n",
        "        Description: This function will train all the models on the given feature set of the X (data) for predicting y (target)\n",
        "\n",
        "        Args: \n",
        "            X => pd.DataFrame object containing the data\n",
        "            y => pd.Series object containings the target classifications\n",
        "            feature_set => list of features in X to use for training\n",
        "\n",
        "        Returns:\n",
        "            metrics => dictionary where the model names are the key and a list of accuracies across all folds is the value\n",
        "                    Keys:\n",
        "                        Random Forest => rf\n",
        "                        Decision Tree => dt\n",
        "                        k-Nearest Neighbors => knn\n",
        "                        Support Vector Machine => svm\n",
        "                        Logistic Regression => lr\n",
        "                        Linear Discriminant Analysis => lda\n",
        "                        AdaBoost => ab\n",
        "                        Naive Bayes => nb\n",
        "                        Keras-TensorFlow => keras\n",
        "                        Fast.ai => fastai\n",
        "    \"\"\"\n",
        "    metrics = {'rf':[],\n",
        "                'dt':[],\n",
        "                'knn':[],\n",
        "                'svm':[],\n",
        "                'lr':[],\n",
        "                'lda':[],\n",
        "                'ab':[],\n",
        "                'nb':[],\n",
        "                'keras':[],\n",
        "                'fastai':[]}\n",
        "\n",
        "    # Select the given features within the data\n",
        "    X = X[feature_set]\n",
        "\n",
        "    print('Training with {} features'.format(len(X.columns)))\n",
        "\n",
        "    # Create stratified, 10-fold cross validation object\n",
        "    random_state = 0\n",
        "    sss = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
        "\n",
        "    # Experiment with 10-fold cross validation\n",
        "    for train_idx, test_idx in sss.split(X, y):\n",
        "        # Split the data into the training and testing sets\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        \n",
        "        # Random Forest Model\n",
        "        rf = RandomForestClassifier(random_state=random_state)\n",
        "        rf.fit(X_train, y_train)\n",
        "        score = rf.score(X_test, y_test)\n",
        "        metrics['rf'].append(score)\n",
        "\n",
        "        \"\"\"# Decision Tree Model\n",
        "        dt = DecisionTreeClassifier(random_state=random_state)\n",
        "        dt.fit(X_train, y_train)\n",
        "        score = dt.score(X_test, y_test)\n",
        "        metrics['dt'].append(score)\n",
        "\n",
        "        # k-Nearest Neighbors Model\n",
        "        knn = KNeighborsClassifier()\n",
        "        knn.fit(X_train, y_train)\n",
        "        score = knn.score(X_test, y_test)\n",
        "        metrics['knn'].append(score)\n",
        "\n",
        "        # Support Vector Machine Model\n",
        "        svm = SVC(random_state=random_state)\n",
        "        svm.fit(X_train, y_train)\n",
        "        score = svm.score(X_test, y_test)\n",
        "        metrics['svm'].append(score)\n",
        "\n",
        "        # Logistic Regression Model\n",
        "        lr = LogisticRegression(random_state=random_state)\n",
        "        lr.fit(X_train, y_train)\n",
        "        score = lr.score(X_test, y_test)\n",
        "        metrics['lr'].append(score)\n",
        "\n",
        "        # Linear Discriminant Analysis Model\n",
        "        lda = LinearDiscriminantAnalysis()\n",
        "        lda.fit(X_train, y_train)\n",
        "        score = lda.score(X_test, y_test)\n",
        "        metrics['lda'].append(score)\n",
        "\n",
        "        # AdaBoost Model\n",
        "        ab = AdaBoostClassifier(random_state=random_state)\n",
        "        ab.fit(X_train, y_train)\n",
        "        score = ab.score(X_test, y_test)\n",
        "        metrics['ab'].append(score)\n",
        "\n",
        "        # Naive Bayes Model\n",
        "        nb = GaussianNB()\n",
        "        nb.fit(X_train, y_train)\n",
        "        score = nb.score(X_test, y_test)\n",
        "        metrics['nb'].append(score)\"\"\"\n",
        "\n",
        "        # Keras-TensorFlow DNN Model\n",
        "        dnn_keras = Sequential(layers=[\n",
        "                                 Dense(128, kernel_regularizer=l2(0.001), activation='relu',input_shape=(len(X_train.columns),)),\n",
        "                                 BatchNormalization(),\n",
        "                                 Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "                                 BatchNormalization(),\n",
        "                                 Dense(y_train.nunique(), activation='softmax')\n",
        "        ])\n",
        "        dnn_keras.compile(\n",
        "            optimizer='adam', \n",
        "            loss='categorical_crossentropy', \n",
        "            metrics=['accuracy'])\n",
        "        dnn_keras.fit(X_train, pd.get_dummies(y_train), epochs=100, verbose=0, batch_size=512)\n",
        "        _, score = dnn_keras.evaluate(X_test, pd.get_dummies(y_test), verbose=0)\n",
        "        metrics['keras'].append(score)\n",
        "\n",
        "        # Fast.ai DNN Model\n",
        "        data_fold = (TabularList.from_df(df, path=path, cont_names=X_train.columns, procs=[Categorify, Normalize])\n",
        "                     .split_by_idxs(train_idx, test_idx)\n",
        "                     .label_from_df(cols=dep_var)\n",
        "                     .databunch(num_workers=0))\n",
        "        dnn_fastai = tabular_learner(data_fold, layers=[200, 100], metrics=accuracy)\n",
        "        dnn_fastai.fit_one_cycle(cyc_len=10, callbacks=None)\n",
        "        _, score = dnn_fastai.validate()\n",
        "        metrics['fastai'].append(score)\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDmSCPgDM-WZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_graph(figure, feature_count, metrics_dict, exp_type=''):\n",
        "  \"\"\"\n",
        "  show_graph function\n",
        "\n",
        "    Description: This function will take the metrics dictionary provided and update the graph already to show the most recent results\n",
        "\n",
        "    Args:\n",
        "      figure => matplotlib.pyplot.figure object\n",
        "      metrics_dict => dictionary of metrics as described in `train_and_eval_on` function\n",
        "      exp_type => string indicating the type of experiment to change the title of the graph\n",
        "\n",
        "    Returns:\n",
        "      nothing\n",
        "  \"\"\"\n",
        "  # Reorganize the data so we have all of the random forest metrics with increasing features side by side\n",
        "  reorganized_dictionary = {}\n",
        "\n",
        "  for feature_vals in metrics_dict.keys():\n",
        "    for key in metrics_dict[feature_vals].keys():\n",
        "      # If a given model is not in the new dictionary, add it\n",
        "      if key not in reorganized_dictionary:\n",
        "        reorganized_dictionary[key] = {}\n",
        "\n",
        "      # If there isn't a specific feature number in the model dictionary, add it\n",
        "      if feature_vals not in reorganized_dictionary[key]:\n",
        "        reorganized_dictionary[key][feature_vals] = []\n",
        "\n",
        "      # If there is anything to the record, add it\n",
        "      if len( metrics_dict[feature_vals][key] ) > 0:\n",
        "        accuracies = metrics_dict[feature_vals][key]\n",
        "        mean = np.mean(accuracies)\n",
        "        std = np.std(accuracies)\n",
        "\n",
        "        #print('Accuracies: {}'.format(accuracies))\n",
        "        #print('Mean: {}'.format(mean))\n",
        "        #print('Std: {}'.format(std))\n",
        "\n",
        "        reorganized_dictionary[key][feature_vals].append( [mean, std] ) \n",
        "\n",
        "  #print('Models: {}'.format( list(reorganized_dictionary.keys()) ))\n",
        "\n",
        "  for model in reorganized_dictionary.keys():\n",
        "    # The x-axis will have the feature_count\n",
        "    xs = []\n",
        "\n",
        "    # The y-axis will have the accuracy for that feature_count value\n",
        "    ys = []\n",
        "\n",
        "    # The y-axis will also have the std for these accuracies since they are accumulated over 10 folds\n",
        "    yerrs = []\n",
        "\n",
        "    for x in reorganized_dictionary[model].keys():\n",
        "      if len(reorganized_dictionary[model][x]) > 0:\n",
        "        xs.append(x)\n",
        "        ys.append(reorganized_dictionary[model][x][0][0])\n",
        "        yerrs.append(reorganized_dictionary[model][x][0][1])\n",
        "    #print('xs: {}'.format(xs))\n",
        "    #print('ys: {}'.format(ys))\n",
        "    if len(xs) > 0:\n",
        "      plt.errorbar(x=xs, y=ys, yerr=yerrs, label=model)\n",
        "\n",
        "  #print(reorganized_dictionary)\n",
        "  if exp_type == 'multi':\n",
        "    plt.title('Multi-class Classification Model Accuracies with Increasing Features')\n",
        "  elif exp_type == 'binary':\n",
        "    plt.title('Binary Classification Model Accuracies with Increasing Features')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Number of Features')\n",
        "\n",
        "  plt.xticks(xs)\n",
        "\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUHx26nlKFKi",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x99zWY_9KFKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These are the best features for multi-class experiment provided from the feature selection jupyter notebook\n",
        "best_features_multiclass = ['Entropy_Afterpath', 'argPathRatio', 'NumberRate_AfterPath', 'NumberRate_Domain', 'ArgUrlRatio', 'Extension_DigitCount', 'dld_getArg', 'ldl_getArg', 'Query_DigitCount', 'LongestVariableValue', 'Querylength', 'Query_LetterCount', 'ldl_path', 'ArgLen', 'ldl_url', 'dld_path', 'Extension_LetterCount', 'argDomanRatio', 'dld_url', 'URL_DigitCount', 'LongestPathTokenLength', 'URLQueries_variable', 'fileNameLen', 'delimeter_Count', 'NumberRate_URL', 'SymbolCount_Domain', 'domain_token_count', 'tld', 'SymbolCount_Extension', 'this.fileExtLen', 'pathLength', 'subDirLen', 'urlLen', 'charcompace', 'host_DigitCount', 'SymbolCount_Afterpath', 'URL_Letter_Count', 'pathDomainRatio', 'SymbolCount_FileName', 'domainUrlRatio', 'NumberRate_Extension', 'NumberRate_FileName', 'SymbolCount_URL', 'Entropy_Filename', 'Entropy_DirectoryName', 'delimeter_path', 'Arguments_LongestWordLength', 'charcompvowels', 'CharacterContinuityRate', 'spcharUrl', 'executable', 'pathurlRatio', 'Filename_LetterCount', 'Entropy_Extension', 'dld_filename', 'ldl_filename', 'SymbolCount_Directoryname', 'avgdomaintokenlen', 'path_token_count', 'File_name_DigitCount', 'NumberRate_DirectoryName', 'delimeter_Domain', 'Domain_LongestWordLength', 'NumberofDotsinURL', 'Directory_DigitCount', 'Directory_LetterCount', 'URL_sensitiveWord', 'longdomaintokenlen', 'ldl_domain', 'domainlength', 'Entropy_Domain', 'host_letter_count', 'avgpathtokenlen', 'isPortEighty', 'sub-Directory_LongestWordLength', 'dld_domain', 'Path_LongestWordLength', 'Entropy_URL']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1oB1IhaKFKs",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIoBo8BsKPMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "bd9666ae-7ec2-420b-b6f7-ddefbb9bd1ed"
      },
      "source": [
        "# Set up google drive access\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "jJ62Jh9HKFKu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a26cc32c-1c90-4ce4-8f15-f81fa08cd650"
      },
      "source": [
        "# Import the data\n",
        "path = '/content/gdrive/My Drive/FinalDataset/'\n",
        "fille = 'All.csv'\n",
        "df = pd.read_csv(path + fille)\n",
        "print('Data Read:')\n",
        "print(df.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Read:\n",
            "   Querylength  domain_token_count  ...  Entropy_Afterpath  URL_Type_obf_Type\n",
            "0            0                   4  ...               -1.0         Defacement\n",
            "1            0                   4  ...               -1.0         Defacement\n",
            "2            0                   4  ...               -1.0         Defacement\n",
            "3            0                   4  ...               -1.0         Defacement\n",
            "4            0                   4  ...               -1.0         Defacement\n",
            "\n",
            "[5 rows x 80 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "0hm6KhlmKFK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12344c64-b48a-4bbf-e750-5402a36f7750"
      },
      "source": [
        "dep_var = 'URL_Type_obf_Type'\n",
        "\n",
        "print('There are {} columns and {} rows in the provided data.'.format(len(df.columns), len(df)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 80 columns and 36697 rows in the provided data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "NulvLK_lKFK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "6337732d-9e0b-42b7-ef12-fdb4e1628e2f"
      },
      "source": [
        "print('Below is the dataset\\'s composition')\n",
        "print(df[dep_var].value_counts())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Below is the dataset's composition\n",
            "Defacement    7930\n",
            "benign        7781\n",
            "phishing      7577\n",
            "malware       6711\n",
            "spam          6698\n",
            "Name: URL_Type_obf_Type, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC4QqIZuKFLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removes all rows if they contain NaN values\n",
        "df.dropna(axis='index', inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "nr-obfDNKFLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "02374253-451f-4731-af2a-c9b2c87d1d08"
      },
      "source": [
        "print('There are {} columns and {} rows in the provided data.'.format(len(df.columns), len(df)))\n",
        "\n",
        "print('Below is the dataset\\'s composition')\n",
        "print(df[dep_var].value_counts())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 80 columns and 18982 rows in the provided data.\n",
            "Below is the dataset's composition\n",
            "spam          5342\n",
            "malware       4440\n",
            "phishing      4014\n",
            "benign        2709\n",
            "Defacement    2477\n",
            "Name: URL_Type_obf_Type, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV6CGdSwKFLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the X (data) and y (labels)\n",
        "X = normalize( df.loc[:, df.columns != dep_var] )\n",
        "y = df[dep_var]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYTGuZiTKFLb",
        "colab_type": "text"
      },
      "source": [
        "## Multi-class Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "R0PDbsRnKFLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cdbe752-8421-4992-f7ce-4cd7690acd34"
      },
      "source": [
        "fig = plt.figure()\n",
        "multi_performance_metrics = {}\n",
        "for i in range(1, 21):\n",
        "    features = best_features_multiclass[:i]\n",
        "    multi_performance_metrics[i] = train_and_eval_on(X=X, y=y, feature_set=features)\n",
        "\n",
        "    #print(performance_metrics)\n",
        "\n",
        "    #show_graph(figure=fig, feature_count=len(features), metrics_dict=multi_performance_metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with 1 features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oee7Ac-sGUHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_graph(figure=fig, feature_count=len(features), metrics_dict=multi_performance_metrics, exp_type='multi')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSCu4rVUBXMx",
        "colab_type": "text"
      },
      "source": [
        "## Binary Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAGsp5rRBPw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the dataset to binary class problem\n",
        "print('Before conversion:')\n",
        "print(y.value_counts())\n",
        "\n",
        "y = y.map(lambda label : label if label == 'benign' else 'malicious')\n",
        "\n",
        "print('After conversion:')\n",
        "print(y.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxqn0sa5ByYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Since we are now in the binary classification problem, we need to assign the feature set from best to worst\n",
        "best_features_binclass = ['fileNameLen', 'domain_token_count', 'tld', 'SymbolCount_Domain', 'Entropy_Afterpath', 'delimeter_path', 'argPathRatio', 'Entropy_Filename', 'Entropy_DirectoryName', 'Filename_LetterCount', 'NumberRate_AfterPath', 'NumberRate_Extension', 'Entropy_Extension', 'ArgUrlRatio', 'NumberRate_FileName', 'dld_getArg', 'CharacterContinuityRate', 'NumberRate_DirectoryName', 'dld_filename', 'Extension_DigitCount', 'NumberRate_Domain', 'domainUrlRatio', 'dld_path', 'ldl_getArg', 'SymbolCount_URL', 'Query_DigitCount', 'dld_url', 'ldl_url', 'ldl_path', 'SymbolCount_Directoryname', 'ArgLen', 'this.fileExtLen', 'Querylength', 'File_name_DigitCount', 'Query_LetterCount', 'LongestVariableValue', 'Extension_LetterCount', 'domainlength', 'NumberofDotsinURL', 'Entropy_Domain', 'path_token_count', 'Directory_DigitCount', 'ldl_filename', 'URLQueries_variable', 'delimeter_Count', 'argDomanRatio', 'SymbolCount_FileName', 'host_DigitCount', 'SymbolCount_Extension', 'pathurlRatio', 'host_letter_count', 'URL_DigitCount', 'delimeter_Domain', 'longdomaintokenlen', 'URL_Letter_Count', 'urlLen', 'LongestPathTokenLength', 'URL_sensitiveWord', 'SymbolCount_Afterpath', 'Domain_LongestWordLength', 'pathLength', 'subDirLen', 'executable', 'spcharUrl', 'Arguments_LongestWordLength', 'avgpathtokenlen', 'charcompace', 'ldl_domain', 'Entropy_URL', 'isPortEighty', 'Directory_LetterCount', 'pathDomainRatio', 'dld_domain', 'NumberRate_URL', 'sub-Directory_LongestWordLength', 'Path_LongestWordLength', 'charcompvowels', 'avgdomaintokenlen']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuWXGJENBQtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "bin_performance_metrics = {}\n",
        "for i in range(1, 21):\n",
        "    features = best_features_binclass[:i]\n",
        "    bin_performance_metrics[i] = train_and_eval_on(X=X, y=y, feature_set=features)\n",
        "\n",
        "    #print(performance_metrics)\n",
        "\n",
        "    #show_graph(figure=fig, feature_count=len(features), metrics_dict=bin_performance_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD27h28qG0xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_graph(figure=fig, feature_count=len(features), metrics_dict=bin_performance_metrics, exp_type='binary')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}