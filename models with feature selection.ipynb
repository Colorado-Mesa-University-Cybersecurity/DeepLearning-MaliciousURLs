{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clays run all timing",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2M8Kl9jhO3O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "b9a9e744-b032-4c9e-bfd4-9fda12c2dcef"
      },
      "source": [
        "# Import the dataset saved on the google drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Data management\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# For S-10-fold CV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Random Forest model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import recall_score, precision_score\n",
        "from keras.metrics import BinaryAccuracy, CategoricalAccuracy, Precision, Recall\n",
        "\n",
        "# Keras DNN Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import BatchNormalization, Dense, Dropout\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import to_categorical, normalize\n",
        "\n",
        "# Fast.ai DNN Model\n",
        "from fastai.tabular import *\n",
        "\n",
        "# For timing of the models across different runtimes (CPU, GPU, TPU)\n",
        "from time import time\n",
        "\n",
        "# Uncomment when using GPU\n",
        "\"\"\"# Set up for GPU Usage\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\"\"\"\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "print('Imports complete.')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.3.0\n",
            "Running on TPU  ['10.20.57.18:8470']\n",
            "WARNING:tensorflow:TPU system grpc://10.20.57.18:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.20.57.18:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.20.57.18:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.20.57.18:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Imports complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK8SH-XVRIGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "14a7af8c-56aa-4acd-e3ac-700b89d85993"
      },
      "source": [
        "# Uncomment when using GPU\n",
        "\"\"\"# Test the GPU\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\"\"\""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'# Test the GPU\\n%tensorflow_version 2.x\\nimport tensorflow as tf\\nimport timeit\\n\\ndevice_name = tf.test.gpu_device_name()\\nif device_name != \\'/device:GPU:0\\':\\n  print(\\n      \\'\\n\\nThis error most likely means that this notebook is not \\'\\n      \\'configured to use a GPU.  Change this in Notebook Settings via the \\'\\n      \\'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n\\')\\n  raise SystemError(\\'GPU device not found\\')\\n\\ndef cpu():\\n  with tf.device(\\'/cpu:0\\'):\\n    random_image_cpu = tf.random.normal((100, 100, 100, 3))\\n    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\\n    return tf.math.reduce_sum(net_cpu)\\n\\ndef gpu():\\n  with tf.device(\\'/device:GPU:0\\'):\\n    random_image_gpu = tf.random.normal((100, 100, 100, 3))\\n    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\\n    return tf.math.reduce_sum(net_gpu)\\n  \\n# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\\ncpu()\\ngpu()\\n\\n# Run the op several times.\\nprint(\\'Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images \\'\\n      \\'(batch x height x width x channel). Sum of ten runs.\\')\\nprint(\\'CPU (s):\\')\\ncpu_time = timeit.timeit(\\'cpu()\\', number=10, setup=\"from __main__ import cpu\")\\nprint(cpu_time)\\nprint(\\'GPU (s):\\')\\ngpu_time = timeit.timeit(\\'gpu()\\', number=10, setup=\"from __main__ import gpu\")\\nprint(gpu_time)\\nprint(\\'GPU speedup over CPU: {}x\\'.format(int(cpu_time/gpu_time)))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKIJdH9xitcv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97ccb17d-c155-48c9-c861-a82a733e6e3c"
      },
      "source": [
        "# Set up google drive access\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvhGygDai7gA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "181a1d4f-65f5-4c87-8225-0610fd97b4b5"
      },
      "source": [
        "# Import the data\n",
        "path = '/content/gdrive/My Drive/FinalDataset/'\n",
        "fille = 'All.csv'\n",
        "df = pd.read_csv(path + fille)\n",
        "print('Data Read:')\n",
        "print(df.head())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Read:\n",
            "   Querylength  domain_token_count  ...  Entropy_Afterpath  URL_Type_obf_Type\n",
            "0            0                   4  ...               -1.0         Defacement\n",
            "1            0                   4  ...               -1.0         Defacement\n",
            "2            0                   4  ...               -1.0         Defacement\n",
            "3            0                   4  ...               -1.0         Defacement\n",
            "4            0                   4  ...               -1.0         Defacement\n",
            "\n",
            "[5 rows x 80 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXDYjLq6ue2p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "075c3036-caad-47f9-e502-60ac94a47def"
      },
      "source": [
        "dep_var = 'URL_Type_obf_Type'\n",
        "\n",
        "print('There are {} columns and {} rows in the provided data.'.format(len(df.columns), len(df)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 80 columns and 36697 rows in the provided data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w3gy187vxL8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "bd81317b-aff2-40c7-e1bc-99939636b69c"
      },
      "source": [
        "print('Below is the dataset\\'s composition')\n",
        "print(df[dep_var].value_counts())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Below is the dataset's composition\n",
            "Defacement    7930\n",
            "benign        7781\n",
            "phishing      7577\n",
            "malware       6711\n",
            "spam          6698\n",
            "Name: URL_Type_obf_Type, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFEW8BQ0rsWb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0056c5b7-d7fa-478f-bc33-3154e0b94c95"
      },
      "source": [
        "nans = 0\n",
        "\n",
        "# This is a kind of stupid way of counting how many NaNs show up within the data\n",
        "for index, row in df.iterrows():\n",
        "  for col in df.columns:\n",
        "    if col == dep_var:\n",
        "      continue\n",
        "\n",
        "    #print(row[col], end=' ')\n",
        "    # If the value is NaN, then mark add one to our counter\n",
        "    if np.isnan(row[col]):\n",
        "     nans += 1\n",
        "  #print('')\n",
        "print('NaNs detected: {}'.format(nans))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NaNs detected: 19153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKdioVPDvr4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removes all rows if they contain NaN values\n",
        "df.dropna(axis='index', inplace=True)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXETwj49wVZ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "880540ce-bca9-496e-c298-ef1ccdb0dbe3"
      },
      "source": [
        "print('There are {} columns and {} rows in the provided data.'.format(len(df.columns), len(df)))\n",
        "\n",
        "print('Below is the dataset\\'s composition')\n",
        "print(df[dep_var].value_counts())\n",
        "\n",
        "nans = 0\n",
        "\n",
        "# This is a kind of stupid way of counting how many NaNs show up within the data\n",
        "for index, row in df.iterrows():\n",
        "  for col in df.columns:\n",
        "    if col == dep_var:\n",
        "      continue\n",
        "\n",
        "    #print(row[col], end=' ')\n",
        "    # If the value is NaN, then mark add one to our counter\n",
        "    if np.isnan(row[col]):\n",
        "     nans += 1\n",
        "  #print('')\n",
        "print('NaNs detected: {}'.format(nans))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 80 columns and 18982 rows in the provided data.\n",
            "Below is the dataset's composition\n",
            "spam          5342\n",
            "malware       4440\n",
            "phishing      4014\n",
            "benign        2709\n",
            "Defacement    2477\n",
            "Name: URL_Type_obf_Type, dtype: int64\n",
            "NaNs detected: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2kgLJFGkTWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the X (data) and y (labels)\n",
        "X = normalize( df.loc[:, df.columns != dep_var] )\n",
        "y = df[dep_var]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E0GT8cKkxrM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "9321dde7-3130-452f-ebf6-462b3f9d3401"
      },
      "source": [
        "print(X.head())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Querylength  domain_token_count  ...  Entropy_Extension  Entropy_Afterpath\n",
            "35     0.000000            0.045198  ...           0.011299          -0.011299\n",
            "37     0.117281            0.021324  ...           0.004037           0.003994\n",
            "38     0.121354            0.021105  ...           0.003990           0.003948\n",
            "39     0.117281            0.021324  ...           0.004000           0.003953\n",
            "40     0.121354            0.021105  ...           0.003990           0.003948\n",
            "\n",
            "[5 rows x 79 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_a3pK4Mkz9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "6c9bf716-93b5-4d49-b258-8ff4649efe9e"
      },
      "source": [
        "print(y.head())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35    Defacement\n",
            "37    Defacement\n",
            "38    Defacement\n",
            "39    Defacement\n",
            "40    Defacement\n",
            "Name: URL_Type_obf_Type, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNqaiHTLjtIg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "426fe089-86b5-446f-86ac-429f5bd4023c"
      },
      "source": [
        "# Create the stratified cross validation object\n",
        "random_state = 0\n",
        "sss = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
        "print(sss)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVC8bNBvjAYB",
        "colab_type": "text"
      },
      "source": [
        "## Multi-Classification Experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJS0BY3fjpXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "9b8c1877-e59c-4d0a-b9e8-2bb23dfcf3cb"
      },
      "source": [
        "fold = 0\n",
        "training_times = {'rf': [], \n",
        "                  'keras': [],\n",
        "                  'fastai': []}\n",
        "\n",
        "for train_idx, test_idx in sss.split(X, y):\n",
        "  # Update which fold we are on (this is just for output/usability reasons)\n",
        "  fold += 1\n",
        "\n",
        "  # Split the data into the train and testing sets\n",
        "  X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "  y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "  # Initialize the models (not fast.ai since it needs a databunch object)\n",
        "  rf = RandomForestClassifier(random_state=random_state)\n",
        "  dnn_keras = Sequential(layers=[\n",
        "                                 Dense(128, kernel_regularizer=l2(0.001), activation='relu',input_shape=(len(X_train.columns),)),\n",
        "                                 BatchNormalization(),\n",
        "                                 Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "                                 BatchNormalization(),\n",
        "                                 Dense(y_train.nunique(), activation='softmax')\n",
        "  ])\n",
        "  dnn_keras.compile(\n",
        "      optimizer='adam', \n",
        "      loss='categorical_crossentropy', \n",
        "      metrics=['accuracy', 'Recall', 'Precision'])\n",
        "  \n",
        "  print('Training RandomForest model with Fold {}...'.format(fold), end='')\n",
        "  t0 = time()\n",
        "  rf.fit(X_train, y_train)\n",
        "  t1 = time()\n",
        "  training_times['rf'].append(t1-t0)\n",
        "  print('done')\n",
        "\n",
        "  print('Training Keras-TensorFlow DNN model with Fold {}...'.format(fold), end='')\n",
        "  t0 = time()\n",
        "  dnn_keras.fit(X_train, pd.get_dummies(y_train), epochs=100, verbose=0, batch_size=1024)\n",
        "  t1 = time()\n",
        "  training_times['keras'].append(t1-t0)\n",
        "  print('done')\n",
        "\n",
        "  # Initialize and run fast.ai model\n",
        "  print('Training Fast.ai Fold {}...'.format(fold))\n",
        "  data_fold = (TabularList.from_df(df, path=path, cont_names=X_train.columns, procs=[Categorify, Normalize])\n",
        "                     .split_by_idxs(train_idx, test_idx)\n",
        "                     .label_from_df(cols=dep_var)\n",
        "                     .databunch())\n",
        "  dnn_fastai = tabular_learner(data_fold, layers=[200, 100], metrics=accuracy)\n",
        "\n",
        "  t0 = time()\n",
        "  dnn_fastai.fit_one_cycle(cyc_len=10, callbacks=None)\n",
        "  t1 = time()\n",
        "  training_times['fastai'].append(t1-t0)\n",
        "  print('Fast ai done')\n",
        "  break\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training RandomForest model with Fold 1...done\n",
            "Training Keras-TensorFlow DNN model with Fold 1...done\n",
            "Training Fast.ai Fold 1...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.448715</td>\n",
              "      <td>0.342088</td>\n",
              "      <td>0.876777</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.298274</td>\n",
              "      <td>0.271093</td>\n",
              "      <td>0.894155</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.258733</td>\n",
              "      <td>0.233258</td>\n",
              "      <td>0.918378</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.212302</td>\n",
              "      <td>0.173841</td>\n",
              "      <td>0.935756</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.177737</td>\n",
              "      <td>0.144453</td>\n",
              "      <td>0.950500</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.136807</td>\n",
              "      <td>0.122004</td>\n",
              "      <td>0.959452</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.115325</td>\n",
              "      <td>0.106509</td>\n",
              "      <td>0.965245</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.101376</td>\n",
              "      <td>0.090834</td>\n",
              "      <td>0.972091</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.077024</td>\n",
              "      <td>0.086472</td>\n",
              "      <td>0.973144</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.071149</td>\n",
              "      <td>0.086438</td>\n",
              "      <td>0.973144</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Fast ai done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wASaeJbH8Zzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "17c50cb6-a96b-4c0d-bcd6-ef25da965f3d"
      },
      "source": [
        "print('model\\tfold runtime\\ttotal runtime')\n",
        "print('-'*40)\n",
        "for model in training_times.keys():\n",
        "  mean = sum(training_times[model]) / len(training_times[model])\n",
        "  std = np.std(training_times[model])\n",
        "\n",
        "  print('{}\\t{:.2f}\\u00B1{:.2f}s\\t{:.2f}s'.format(model, mean, std, sum(training_times[model])))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model\tfold runtime\ttotal runtime\n",
            "----------------------------------------\n",
            "rf\t8.70±0.00s\t8.70s\n",
            "keras\t12.16±0.00s\t12.16s\n",
            "fastai\t30.96±0.00s\t30.96s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO4CHLTb2KVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e3ff057c-3a3b-4714-f18e-da16b6209fe8"
      },
      "source": [
        "# The models currently hold the last fold's values. We will use these models to predict\n",
        "rf_times = []\n",
        "keras_times = []\n",
        "fastai_times = []\n",
        "\n",
        "for index, row in X_test.iterrows():\n",
        "  t0 = time()\n",
        "  dnn_fastai.predict(row)\n",
        "  t1 = time()\n",
        "  fastai_times.append(t1-t0)\n",
        "\n",
        "  row = ( row.to_numpy() ).reshape(1, -1)\n",
        "  #row = row.reshape(1, -1)\n",
        "  t0 = time()\n",
        "  rf.predict(row)\n",
        "  t1 = time()\n",
        "  rf_times.append(t1-t0)\n",
        "\n",
        "  t0 = time()\n",
        "  dnn_keras.predict(row)\n",
        "  t1 = time()\n",
        "  keras_times.append(t1-t0)\n",
        "\n",
        "rf_avg = np.average(rf_times)\n",
        "rf_std = np.std(rf_times)\n",
        "\n",
        "keras_avg = np.average(keras_times)\n",
        "keras_std = np.std(keras_times)\n",
        "\n",
        "fastai_avg = np.average(fastai_times)\n",
        "fastai_std = np.std(fastai_times)\n",
        "\n",
        "print('Model\\tMean Time per Prediction')\n",
        "print('RF\\t{:.2f}\\u00B1{:.2f}ms'.format(rf_avg*1000, rf_std*1000))\n",
        "print('Keras\\t{:.2f}\\u00B1{:.2f}ms'.format(keras_avg*1000, keras_std*1000))\n",
        "print('Fastai\\t{:.2f}\\u00B1{:.2f}ms'.format(fastai_avg*1000, fastai_std*1000))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model\tMean Time per Prediction\n",
            "RF\t8.02±0.66ms\n",
            "Keras\t41.49±4.32ms\n",
            "Fastai\t54.53±11.05ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5CbPy1EDmiu",
        "colab_type": "text"
      },
      "source": [
        "## Binary Classification\n",
        "This is mostly the same code for the execution of the models, however we have to change the data..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QMUO9xsD17R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "50adf4c0-bd9d-4963-8aa9-63ac5645e5a0"
      },
      "source": [
        "print('There are {} columns and {} rows in the provided data.'.format(len(X.columns)+1, len(X)))\n",
        "\n",
        "print('Below is the dataset\\'s composition')\n",
        "print(y.value_counts())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 80 columns and 18982 rows in the provided data.\n",
            "Below is the dataset's composition\n",
            "spam          5342\n",
            "malware       4440\n",
            "phishing      4014\n",
            "benign        2709\n",
            "Defacement    2477\n",
            "Name: URL_Type_obf_Type, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRH7VGSID_n_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the multiclass problem into a binary classification problem\n",
        "y = y.map(lambda label : label if label == 'benign' else 'malicious')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjSuqlhlEae7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ac53955f-8678-42e3-c393-677a1cd340b1"
      },
      "source": [
        "print('There are {} columns and {} rows in the provided data.'.format(len(X.columns)+1, len(X)))\n",
        "\n",
        "print('Below is the dataset\\'s composition')\n",
        "print(y.value_counts())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 80 columns and 18982 rows in the provided data.\n",
            "Below is the dataset's composition\n",
            "malicious    16273\n",
            "benign        2709\n",
            "Name: URL_Type_obf_Type, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tMhi7CQDoqv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "95a8515f-8ad6-40af-e9b8-554440102218"
      },
      "source": [
        "fold = 0\n",
        "training_times = {'rf': [], \n",
        "                  'keras': [],\n",
        "                  'fastai': []}\n",
        "\n",
        "for train_idx, test_idx in sss.split(X, y):\n",
        "  # Update which fold we are on (this is just for output/usability reasons)\n",
        "  fold += 1\n",
        "\n",
        "  # Split the data into the train and testing sets\n",
        "  X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "  y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "  # Initialize the models (not fast.ai since it needs a databunch object)\n",
        "  rf = RandomForestClassifier(random_state=random_state)\n",
        "  dnn_keras = Sequential(layers=[\n",
        "                                 Dense(128, kernel_regularizer=l2(0.001), activation='relu',input_shape=(len(X_train.columns),)),\n",
        "                                 BatchNormalization(),\n",
        "                                 Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "                                 BatchNormalization(),\n",
        "                                 Dense(y_train.nunique(), activation='softmax')\n",
        "  ])\n",
        "  dnn_keras.compile(\n",
        "      optimizer='adam', \n",
        "      loss='categorical_crossentropy', \n",
        "      metrics=['accuracy', 'Recall', 'Precision'])\n",
        "  \n",
        "  print('Training RandomForest model with Fold {}...'.format(fold), end='')\n",
        "  t0 = time()\n",
        "  rf.fit(X_train, y_train)\n",
        "  t1 = time()\n",
        "  training_times['rf'].append(t1-t0)\n",
        "  print('done')\n",
        "\n",
        "  print('Training Keras-TensorFlow DNN model with Fold {}...'.format(fold), end='')\n",
        "  t0 = time()\n",
        "  dnn_keras.fit(X_train, pd.get_dummies(y_train), epochs=100, verbose=0, batch_size=1024)\n",
        "  t1 = time()\n",
        "  training_times['keras'].append(t1-t0)\n",
        "  print('done')\n",
        "\n",
        "  # Initialize and run fast.ai model\n",
        "  print('Training Fast.ai Fold {}...'.format(fold))\n",
        "  data_fold = (TabularList.from_df(df, path=path, cont_names=X_train.columns, procs=[Categorify, Normalize])\n",
        "                     .split_by_idxs(train_idx, test_idx)\n",
        "                     .label_from_df(cols=dep_var)\n",
        "                     .databunch())\n",
        "  dnn_fastai = tabular_learner(data_fold, layers=[200, 100], metrics=accuracy)\n",
        "\n",
        "  t0 = time()\n",
        "  dnn_fastai.fit_one_cycle(cyc_len=10, callbacks=None)\n",
        "  t1 = time()\n",
        "  training_times['fastai'].append(t1-t0)\n",
        "  print('Fast ai done')\n",
        "  break"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training RandomForest model with Fold 1...done\n",
            "Training Keras-TensorFlow DNN model with Fold 1...done\n",
            "Training Fast.ai Fold 1...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.458214</td>\n",
              "      <td>0.336439</td>\n",
              "      <td>0.890469</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.298138</td>\n",
              "      <td>0.251246</td>\n",
              "      <td>0.910479</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.252527</td>\n",
              "      <td>0.246379</td>\n",
              "      <td>0.909953</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.214199</td>\n",
              "      <td>0.212769</td>\n",
              "      <td>0.931016</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.170784</td>\n",
              "      <td>0.182835</td>\n",
              "      <td>0.939968</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.144108</td>\n",
              "      <td>0.154774</td>\n",
              "      <td>0.953660</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.116634</td>\n",
              "      <td>0.133819</td>\n",
              "      <td>0.958399</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.097174</td>\n",
              "      <td>0.122703</td>\n",
              "      <td>0.962085</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.080235</td>\n",
              "      <td>0.116013</td>\n",
              "      <td>0.962085</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.072025</td>\n",
              "      <td>0.112126</td>\n",
              "      <td>0.964192</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Fast ai done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SphtzejIE3iV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "d40e9188-2596-4ff9-fdb4-48c60a0d0754"
      },
      "source": [
        "print('model\\tfold runtime\\ttotal runtime')\n",
        "print('-'*40)\n",
        "for model in training_times.keys():\n",
        "  mean = sum(training_times[model]) / len(training_times[model])\n",
        "  std = np.std(training_times[model])\n",
        "\n",
        "  print('{}\\t{:.2f}\\u00B1{:.2f}s\\t{:.2f}s'.format(model, mean, std, sum(training_times[model])))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model\tfold runtime\ttotal runtime\n",
            "----------------------------------------\n",
            "rf\t7.58±0.00s\t7.58s\n",
            "keras\t11.96±0.00s\t11.96s\n",
            "fastai\t30.74±0.00s\t30.74s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yq6hAvd2rD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "00149f46-40ae-4900-80b9-20a113ee164f"
      },
      "source": [
        "# The models currently hold the last fold's values. We will use these models to predict\n",
        "rf_times = []\n",
        "keras_times = []\n",
        "fastai_times = []\n",
        "\n",
        "for index, row in X_test.iterrows():\n",
        "  t0 = time()\n",
        "  dnn_fastai.predict(row)\n",
        "  t1 = time()\n",
        "  fastai_times.append(t1-t0)\n",
        "\n",
        "  row = ( row.to_numpy() ).reshape(1, -1)\n",
        "  #row = row.reshape(1, -1)\n",
        "  t0 = time()\n",
        "  rf.predict(row)\n",
        "  t1 = time()\n",
        "  rf_times.append(t1-t0)\n",
        "\n",
        "  t0 = time()\n",
        "  dnn_keras.predict(row)\n",
        "  t1 = time()\n",
        "  keras_times.append(t1-t0)\n",
        "\n",
        "rf_avg = np.average(rf_times)\n",
        "rf_std = np.std(rf_times)\n",
        "\n",
        "keras_avg = np.average(keras_times)\n",
        "keras_std = np.std(keras_times)\n",
        "\n",
        "fastai_avg = np.average(fastai_times)\n",
        "fastai_std = np.std(fastai_times)\n",
        "\n",
        "print('Model\\tMean Time per Prediction')\n",
        "print('RF\\t{:.2f}\\u00B1{:.2f}ms'.format(rf_avg*1000, rf_std*1000))\n",
        "print('Keras\\t{:.2f}\\u00B1{:.2f}ms'.format(keras_avg*1000, keras_std*1000))\n",
        "print('Fastai\\t{:.2f}\\u00B1{:.2f}ms'.format(fastai_avg*1000, fastai_std*1000))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model\tMean Time per Prediction\n",
            "RF\t7.99±0.74ms\n",
            "Keras\t41.52±4.30ms\n",
            "Fastai\t54.59±8.88ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}