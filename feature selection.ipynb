{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "# Feature selection \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read:\n",
      "   Querylength  domain_token_count  path_token_count  avgdomaintokenlen  \\\n",
      "0            0                   4                 5                5.5   \n",
      "1            0                   4                 5                5.5   \n",
      "2            0                   4                 5                5.5   \n",
      "3            0                   4                12                5.5   \n",
      "4            0                   4                 6                5.5   \n",
      "\n",
      "   longdomaintokenlen  avgpathtokenlen  tld  charcompvowels  charcompace  \\\n",
      "0                  14         4.400000    4               8            3   \n",
      "1                  14         6.000000    4              12            4   \n",
      "2                  14         5.800000    4              12            5   \n",
      "3                  14         5.500000    4              32           16   \n",
      "4                  14         7.333334    4              18           11   \n",
      "\n",
      "   ldl_url  ...  SymbolCount_FileName  SymbolCount_Extension  \\\n",
      "0        0  ...                     1                      0   \n",
      "1        0  ...                     0                      0   \n",
      "2        0  ...                     0                      0   \n",
      "3        0  ...                     0                      0   \n",
      "4        0  ...                     0                      0   \n",
      "\n",
      "   SymbolCount_Afterpath  Entropy_URL  Entropy_Domain  Entropy_DirectoryName  \\\n",
      "0                     -1     0.726298        0.784493               0.894886   \n",
      "1                     -1     0.688635        0.784493               0.814725   \n",
      "2                     -1     0.695049        0.784493               0.814725   \n",
      "3                     -1     0.640130        0.784493               0.814725   \n",
      "4                     -1     0.681307        0.784493               0.814725   \n",
      "\n",
      "   Entropy_Filename  Entropy_Extension  Entropy_Afterpath  URL_Type_obf_Type  \n",
      "0          0.850608                NaN               -1.0         Defacement  \n",
      "1          0.859793                0.0               -1.0         Defacement  \n",
      "2          0.801880                0.0               -1.0         Defacement  \n",
      "3          0.663210                0.0               -1.0         Defacement  \n",
      "4          0.804526                0.0               -1.0         Defacement  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the data\n",
    "path = '/media/notclaytonjohnson/Seagate Portable Drive/Data/urls_dataset/'\n",
    "fille = 'All.csv'\n",
    "df = pd.read_csv(path + fille)\n",
    "\n",
    "print('Data read:')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 80 columns and 36707 rows in the provided data.\n"
     ]
    }
   ],
   "source": [
    "dep_var = 'URL_Type_obf_Type'\n",
    "\n",
    "print('There are {} columns and {} rows in the provided data.'.format(len(df.columns), len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the dataset's composition\n",
      "Defacement    7930\n",
      "benign        7781\n",
      "phishing      7586\n",
      "malware       6712\n",
      "spam          6698\n",
      "Name: URL_Type_obf_Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Below is the dataset\\'s composition')\n",
    "print(df[dep_var].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes all rows if they contain NaN values\n",
    "df.dropna(axis='index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 80 columns and 18982 rows in the provided data.\n",
      "Below is the dataset's composition\n",
      "spam          5342\n",
      "malware       4440\n",
      "phishing      4014\n",
      "benign        2709\n",
      "Defacement    2477\n",
      "Name: URL_Type_obf_Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('There are {} columns and {} rows in the provided data.'.format(len(df.columns), len(df)))\n",
    "\n",
    "print('Below is the dataset\\'s composition')\n",
    "print(df[dep_var].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the X (data) and y (labels)\n",
    "#X = pd.DataFrame( normalize(df.loc[:, df.columns != dep_var]), columns=df.columns[:-1] )\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame( scaler.fit_transform(df.loc[:, df.columns != dep_var]), columns=df.columns[:-1] )\n",
    "\n",
    "y = df[dep_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Querylength  domain_token_count  path_token_count  avgdomaintokenlen  \\\n",
      "0     0.000000            0.153846           0.00000           0.177083   \n",
      "1     0.015884            0.153846           0.09375           0.177083   \n",
      "2     0.016606            0.153846           0.09375           0.177083   \n",
      "3     0.015884            0.153846           0.09375           0.177083   \n",
      "4     0.016606            0.153846           0.09375           0.177083   \n",
      "\n",
      "   longdomaintokenlen  avgpathtokenlen       tld  charcompvowels  charcompace  \\\n",
      "0            0.245902         0.083969  0.153846        0.020725     0.014085   \n",
      "1            0.245902         0.076336  0.153846        0.098446     0.070423   \n",
      "2            0.245902         0.076336  0.153846        0.098446     0.070423   \n",
      "3            0.245902         0.076336  0.153846        0.098446     0.070423   \n",
      "4            0.245902         0.076336  0.153846        0.098446     0.070423   \n",
      "\n",
      "   ldl_url  ...  SymbolCount_Directoryname  SymbolCount_FileName  \\\n",
      "0      0.0  ...                       0.08              0.058824   \n",
      "1      0.0  ...                       0.08              0.294118   \n",
      "2      0.0  ...                       0.08              0.294118   \n",
      "3      0.0  ...                       0.08              0.294118   \n",
      "4      0.0  ...                       0.08              0.294118   \n",
      "\n",
      "   SymbolCount_Extension  SymbolCount_Afterpath  Entropy_URL  Entropy_Domain  \\\n",
      "0               0.030303               0.000000     0.702254        0.396183   \n",
      "1               0.272727               0.195122     0.609821        0.396183   \n",
      "2               0.272727               0.195122     0.611647        0.396183   \n",
      "3               0.272727               0.195122     0.602944        0.396183   \n",
      "4               0.272727               0.195122     0.611647        0.396183   \n",
      "\n",
      "   Entropy_DirectoryName  Entropy_Filename  Entropy_Extension  \\\n",
      "0               0.976656          1.000000           1.000000   \n",
      "1               0.976656          0.874053           0.878603   \n",
      "2               0.976656          0.873811           0.878149   \n",
      "3               0.976656          0.871045           0.875146   \n",
      "4               0.976656          0.873811           0.878149   \n",
      "\n",
      "   Entropy_Afterpath  \n",
      "0           0.000000  \n",
      "1           0.874583  \n",
      "2           0.874134  \n",
      "3           0.870753  \n",
      "4           0.874134  \n",
      "\n",
      "[5 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35    Defacement\n",
      "37    Defacement\n",
      "38    Defacement\n",
      "39    Defacement\n",
      "40    Defacement\n",
      "Name: URL_Type_obf_Type, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin the feature selection process using the SelectKBest object from scikit-learn\n",
    "X_new = SelectKBest(chi2, k=10).fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.03871459 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.4821902  ... 0.         0.54255319 0.87458339]\n",
      " [0.         0.         0.48757384 ... 0.         0.55208333 0.87413385]\n",
      " ...\n",
      " [0.08695652 0.38709677 0.75902627 ... 0.         0.51470588 0.85262228]\n",
      " [0.03381643 0.12903226 0.62794394 ... 0.         0.70909091 0.89538585]\n",
      " [0.0821256  0.19354839 0.74120529 ... 0.         0.53       0.88461893]]\n"
     ]
    }
   ],
   "source": [
    "print(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print('The data presented in this block is bad statistics!')\\n\\nselect = SelectKBest(chi2, k='all')\\nfit = select.fit(X, y)\\n\\ndictt = []\\ni=0\\nremoved_columns = []\\nfor col in X.columns:\\n    score = fit.scores_[i]\\n    #print(score)\\n    i+=1\\n    if not np.isnan(float(score)):\\n        dictt.append([col, score])    \\n    else:\\n        removed_columns.append(col)\\n#dictt = sorted(dictt, key=operator.itemgetter(1), reverse=True)\\ndictt.sort(key=lambda arr : float(arr[1]), reverse=True)\\n\\noutstr = ''\\ni=1\\nfor col, score in dictt:\\n    #if not math.isnan(float(score)):\\n    print('{}\\t{}\\t{}'.format(i, col, score))\\n    i+=1\\n    outstr += ''' + col + '', '\\n\\nif len(removed_columns) > 0:\\n    print('Removed columns: {}'.format(removed_columns))\\nprint('Columns in order from best to worst: {}'.format(outstr[:-2]))\\n\\nprint('The data presented in this block is bad statistics!')\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print('The data presented in this block is bad statistics!')\n",
    "\n",
    "select = SelectKBest(chi2, k='all')\n",
    "fit = select.fit(X, y)\n",
    "\n",
    "dictt = []\n",
    "i=0\n",
    "removed_columns = []\n",
    "for col in X.columns:\n",
    "    score = fit.scores_[i]\n",
    "    #print(score)\n",
    "    i+=1\n",
    "    if not np.isnan(float(score)):\n",
    "        dictt.append([col, score])    \n",
    "    else:\n",
    "        removed_columns.append(col)\n",
    "#dictt = sorted(dictt, key=operator.itemgetter(1), reverse=True)\n",
    "dictt.sort(key=lambda arr : float(arr[1]), reverse=True)\n",
    "\n",
    "outstr = ''\n",
    "i=1\n",
    "for col, score in dictt:\n",
    "    #if not math.isnan(float(score)):\n",
    "    print('{}\\t{}\\t{}'.format(i, col, score))\n",
    "    i+=1\n",
    "    outstr += '\\'' + col + '\\', '\n",
    "\n",
    "if len(removed_columns) > 0:\n",
    "    print('Removed columns: {}'.format(removed_columns))\n",
    "print('Columns in order from best to worst: {}'.format(outstr[:-2]))\n",
    "\n",
    "print('The data presented in this block is bad statistics!')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values in order of descending p-values (higher=more significant)\n",
      "Index(['Entropy_URL', 'Path_LongestWordLength', 'dld_domain',\n",
      "       'sub-Directory_LongestWordLength', 'isPortEighty', 'avgpathtokenlen',\n",
      "       'host_letter_count', 'Entropy_Domain', 'domainlength', 'ldl_domain',\n",
      "       'longdomaintokenlen', 'URL_sensitiveWord', 'Directory_LetterCount',\n",
      "       'Directory_DigitCount', 'NumberofDotsinURL', 'Domain_LongestWordLength',\n",
      "       'delimeter_Domain', 'NumberRate_DirectoryName', 'File_name_DigitCount',\n",
      "       'path_token_count', 'avgdomaintokenlen', 'SymbolCount_Directoryname',\n",
      "       'ldl_filename', 'dld_filename', 'Entropy_Extension',\n",
      "       'Filename_LetterCount', 'pathurlRatio', 'executable', 'spcharUrl',\n",
      "       'CharacterContinuityRate', 'charcompvowels',\n",
      "       'Arguments_LongestWordLength', 'delimeter_path',\n",
      "       'Entropy_DirectoryName', 'Entropy_Filename', 'SymbolCount_URL',\n",
      "       'NumberRate_FileName', 'NumberRate_Extension', 'domainUrlRatio',\n",
      "       'SymbolCount_FileName', 'pathDomainRatio', 'URL_Letter_Count',\n",
      "       'SymbolCount_Afterpath', 'host_DigitCount', 'charcompace', 'urlLen',\n",
      "       'subDirLen', 'pathLength', 'this.fileExtLen', 'SymbolCount_Extension',\n",
      "       'tld', 'domain_token_count', 'SymbolCount_Domain', 'NumberRate_URL',\n",
      "       'delimeter_Count', 'fileNameLen', 'URLQueries_variable',\n",
      "       'LongestPathTokenLength', 'URL_DigitCount', 'dld_url', 'argDomanRatio',\n",
      "       'Extension_LetterCount', 'dld_path', 'ldl_url', 'ArgLen', 'ldl_path',\n",
      "       'Query_LetterCount', 'Querylength', 'LongestVariableValue',\n",
      "       'Query_DigitCount', 'ldl_getArg', 'dld_getArg', 'Extension_DigitCount',\n",
      "       'ArgUrlRatio', 'NumberRate_Domain', 'NumberRate_AfterPath',\n",
      "       'argPathRatio', 'Entropy_Afterpath', 'ISIpAddressInDomainName'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Additions of another work found here: https://towardsdatascience.com/chi-square-test-for-feature-selection-in-machine-learning-206b1f0b8223\n",
    "chi_scores = chi2(X, y)\n",
    "p_values = pd.Series(chi_scores[1],index = X.columns)\n",
    "p_values.sort_values(ascending = False , inplace = True)\n",
    "#p_values.plot.bar()\n",
    "print('Values in order of descending p-values (higher=more significant)')\n",
    "print(p_values.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entropy_URL                        1.272731e-01\n",
       "Path_LongestWordLength             1.380409e-02\n",
       "dld_domain                         4.124519e-04\n",
       "sub-Directory_LongestWordLength    3.440676e-04\n",
       "isPortEighty                       2.881362e-05\n",
       "avgpathtokenlen                    1.192005e-07\n",
       "host_letter_count                  1.007751e-08\n",
       "Entropy_Domain                     6.009946e-09\n",
       "domainlength                       8.353102e-10\n",
       "ldl_domain                         7.808014e-11\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongestVariableValue       2.788998e-135\n",
       "Query_DigitCount           1.118545e-135\n",
       "ldl_getArg                 1.714726e-147\n",
       "dld_getArg                 1.534782e-147\n",
       "Extension_DigitCount       6.874504e-171\n",
       "ArgUrlRatio                3.924478e-272\n",
       "NumberRate_Domain          5.645027e-279\n",
       "NumberRate_AfterPath       1.983143e-290\n",
       "argPathRatio               1.397820e-290\n",
       "Entropy_Afterpath           0.000000e+00\n",
       "ISIpAddressInDomainName              NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values.tail(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Class Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious    16273\n",
      "benign        2709\n",
      "Name: URL_Type_obf_Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = y.map(lambda label : label if label == 'benign' else 'malicious')\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print('The data presented in this block is bad statistics!')\\n\\nselect = SelectKBest(chi2, k='all')\\nfit = select.fit(X, y)\\n\\ndictt = []\\ni=0\\nremoved_columns = []\\nfor col in X.columns:\\n    score = fit.scores_[i]\\n    #print(score)\\n    i+=1\\n    if not np.isnan(float(score)):\\n        dictt.append([col, score])    \\n    else:\\n        removed_columns.append(col)\\n#dictt = sorted(dictt, key=operator.itemgetter(1), reverse=True)\\ndictt.sort(key=lambda arr : float(arr[1]), reverse=True)\\n\\noutstr = ''\\ni=1\\nfor col, score in dictt:\\n    #if not math.isnan(float(score)):\\n    print('{}\\t{}\\t{}'.format(i, col, score))\\n    i+=1\\n    outstr += ''' + col + '', '\\n\\n\\nif len(removed_columns) > 0:\\n    print('Removed columns: {}'.format(removed_columns))\\n\\nprint('Columns in order from best to worst: {}'.format(outstr[:-2]))\\n\\nprint('The data presented in this block is bad statistics!')\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print('The data presented in this block is bad statistics!')\n",
    "\n",
    "select = SelectKBest(chi2, k='all')\n",
    "fit = select.fit(X, y)\n",
    "\n",
    "dictt = []\n",
    "i=0\n",
    "removed_columns = []\n",
    "for col in X.columns:\n",
    "    score = fit.scores_[i]\n",
    "    #print(score)\n",
    "    i+=1\n",
    "    if not np.isnan(float(score)):\n",
    "        dictt.append([col, score])    \n",
    "    else:\n",
    "        removed_columns.append(col)\n",
    "#dictt = sorted(dictt, key=operator.itemgetter(1), reverse=True)\n",
    "dictt.sort(key=lambda arr : float(arr[1]), reverse=True)\n",
    "\n",
    "outstr = ''\n",
    "i=1\n",
    "for col, score in dictt:\n",
    "    #if not math.isnan(float(score)):\n",
    "    print('{}\\t{}\\t{}'.format(i, col, score))\n",
    "    i+=1\n",
    "    outstr += '\\'' + col + '\\', '\n",
    "\n",
    "\n",
    "if len(removed_columns) > 0:\n",
    "    print('Removed columns: {}'.format(removed_columns))\n",
    "\n",
    "print('Columns in order from best to worst: {}'.format(outstr[:-2]))\n",
    "\n",
    "print('The data presented in this block is bad statistics!')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values in order of descending p-values (higher=more significant)\n",
      "Index(['avgdomaintokenlen', 'charcompvowels', 'Path_LongestWordLength',\n",
      "       'sub-Directory_LongestWordLength', 'NumberRate_URL', 'dld_domain',\n",
      "       'pathDomainRatio', 'Directory_LetterCount', 'isPortEighty',\n",
      "       'Entropy_URL', 'ldl_domain', 'charcompace', 'avgpathtokenlen',\n",
      "       'Arguments_LongestWordLength', 'spcharUrl', 'executable', 'subDirLen',\n",
      "       'pathLength', 'Domain_LongestWordLength', 'SymbolCount_Afterpath',\n",
      "       'URL_sensitiveWord', 'LongestPathTokenLength', 'urlLen',\n",
      "       'URL_Letter_Count', 'longdomaintokenlen', 'delimeter_Domain',\n",
      "       'URL_DigitCount', 'host_letter_count', 'pathurlRatio',\n",
      "       'SymbolCount_Extension', 'host_DigitCount', 'SymbolCount_FileName',\n",
      "       'argDomanRatio', 'delimeter_Count', 'URLQueries_variable',\n",
      "       'ldl_filename', 'Directory_DigitCount', 'path_token_count',\n",
      "       'Entropy_Domain', 'NumberofDotsinURL', 'domainlength',\n",
      "       'Extension_LetterCount', 'LongestVariableValue', 'Query_LetterCount',\n",
      "       'File_name_DigitCount', 'Querylength', 'this.fileExtLen', 'ArgLen',\n",
      "       'SymbolCount_Directoryname', 'ldl_path', 'ldl_url', 'dld_url',\n",
      "       'Query_DigitCount', 'SymbolCount_URL', 'ldl_getArg', 'dld_path',\n",
      "       'domainUrlRatio', 'NumberRate_Domain', 'Extension_DigitCount',\n",
      "       'dld_filename', 'NumberRate_DirectoryName', 'CharacterContinuityRate',\n",
      "       'dld_getArg', 'NumberRate_FileName', 'ArgUrlRatio', 'Entropy_Extension',\n",
      "       'NumberRate_Extension', 'NumberRate_AfterPath', 'Filename_LetterCount',\n",
      "       'Entropy_DirectoryName', 'Entropy_Filename', 'argPathRatio',\n",
      "       'delimeter_path', 'Entropy_Afterpath', 'SymbolCount_Domain', 'tld',\n",
      "       'domain_token_count', 'fileNameLen', 'ISIpAddressInDomainName'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Additions of another work found here: https://towardsdatascience.com/chi-square-test-for-feature-selection-in-machine-learning-206b1f0b8223\n",
    "chi_scores = chi2(X, y)\n",
    "p_values = pd.Series(chi_scores[1],index = X.columns)\n",
    "p_values.sort_values(ascending = False , inplace = True)\n",
    "#p_values.plot.bar()\n",
    "print('Values in order of descending p-values (higher=more significant)')\n",
    "print(p_values.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avgdomaintokenlen                  0.993084\n",
       "charcompvowels                     0.911420\n",
       "Path_LongestWordLength             0.868772\n",
       "sub-Directory_LongestWordLength    0.587184\n",
       "NumberRate_URL                     0.442371\n",
       "dld_domain                         0.339682\n",
       "pathDomainRatio                    0.305007\n",
       "Directory_LetterCount              0.265838\n",
       "isPortEighty                       0.248489\n",
       "Entropy_URL                        0.161457\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Filename_LetterCount       3.891527e-33\n",
       "Entropy_DirectoryName      7.487584e-36\n",
       "Entropy_Filename           2.679810e-37\n",
       "argPathRatio               9.901046e-38\n",
       "delimeter_path             9.681864e-40\n",
       "Entropy_Afterpath          3.584071e-41\n",
       "SymbolCount_Domain         1.678641e-41\n",
       "tld                        1.636373e-41\n",
       "domain_token_count         1.636373e-41\n",
       "fileNameLen                1.406341e-70\n",
       "ISIpAddressInDomainName             NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values.tail(11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
